{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code Explains how to connect to elastic search and index in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Environment **\n",
    "\n",
    "Language: Pyhton 3.5\n",
    "\n",
    "Elasticsearch: version 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: \n",
    "    - To run the script, elasticsearch(es) should be running in the backend\n",
    "    - To check es status go to http://localhost:9200/ (if default settings)\n",
    "    \n",
    "Current elasticsearch settings:\n",
    "- Host: localhost\n",
    "- port: 9200\n",
    "- Index: pdf_indexing_docwise_temp\n",
    "- type: documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import required libraries\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "from elasticsearch import helpers\n",
    "\n",
    "#set variables\n",
    "ES_HOST = {\"host\" : \"localhost\", \"port\" : 9200}\n",
    "INDEX_NAME = 'my_index'\n",
    "TYPE_NAME = 'documents'\n",
    "\n",
    "#create connection\n",
    "es = Elasticsearch(hosts = [ES_HOST])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new index\n",
    "\n",
    "This consist of two important steps,\n",
    "- Defining index setting\n",
    "- Defining indexing mapping\n",
    "\n",
    "Note: If settings and mapping not defined, default one's will be created based on input data. Which is not advisable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting 'pdf_indexing_docwise_temp' index...\n",
      "response: '{'acknowledged': True}'\n",
      "creating 'pdf_indexing_docwise_temp' index...\n",
      " response: '{'acknowledged': True}'\n",
      "Mapping.......\n"
     ]
    }
   ],
   "source": [
    "#Check if index already exist. if yes, delete and then create new index\n",
    "\n",
    "if es.indices.exists(INDEX_NAME):\n",
    "    print(\"Deleting '%s' index...\" % (INDEX_NAME))\n",
    "    res = es.indices.delete(index = INDEX_NAME)\n",
    "    print(\"response: '%s'\" % (res))\n",
    "    \n",
    "# Define settings \n",
    "# Explore more on setting in official ES site\n",
    "\n",
    "request_body = {\n",
    "        \"settings\" : {\n",
    "                \"number_of_shards\": 1,\n",
    "                \"number_of_replicas\": 0\n",
    "                }\n",
    "        }\n",
    "\n",
    "#Define mapping\n",
    "# Explore more on mapping in official ES site\n",
    "# Each elements in mapping is called fields\n",
    "\n",
    "mapping = {\n",
    "        \"documents\": {\n",
    "          \"properties\": {\n",
    "            \"content\": {\"type\": \"string\"},\n",
    "            \"title\" : {\"type\": \"string\"},\n",
    "            \"date\" : {\"type\": \"string\"},\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "\n",
    "# create indexing\n",
    "\n",
    "print(\"creating '%s' index...\" % (INDEX_NAME))\n",
    "res = es.indices.create(index = INDEX_NAME, body = request_body)\n",
    "print(\" response: '%s'\" % (res))\n",
    "        \n",
    "# put mapping to created index\n",
    "\n",
    "print(\"Mapping.......\")\n",
    "res = es.indices.put_mapping(\n",
    "    index = INDEX_NAME,\n",
    "    doc_type = TYPE_NAME,\n",
    "    body = mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create sample document for indexing  in required format\n",
    "\n",
    "Note: \n",
    "- Here manually creating document to show how data need to be formated according to mapping for proper indexing \n",
    "\n",
    "Some important points:\n",
    "- If mapping is not defined for a fields, defaults field derived based on first input\n",
    "- While indexing it is not necessary that data should contain all the fields. If not given, field will be updated with empyt/'na'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {\"content\": \"blah blah blah..\",\n",
    "       \"title\":\"tile_name\",\n",
    "       \"data\":\"13/12/2016\"\n",
    "       }\n",
    "\n",
    "# Try to link mapping defined and document above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Push documents to index\n",
    "\n",
    "Note: It is always good to have manually defined ids for each document/data point. If not ES will create its own ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " response: '{'_version': 1, 'created': True, '_index': 'pdf_indexing_docwise_temp', '_id': '0', '_shards': {'failed': 0, 'total': 1, 'successful': 1}, '_type': 'documents'}'\n"
     ]
    }
   ],
   "source": [
    "doc_id = \"0\"\n",
    "res = es.index(index = INDEX_NAME, body = data ,doc_type = TYPE_NAME ,id = doc_id, refresh = True)\n",
    "\n",
    "print(\" response: '%s'\" % (res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update index\n",
    "\n",
    "Code to update existing document\n",
    "\n",
    "Note:\n",
    "- While updating a document, document need to be appended with \"doc\" as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " response: '{'_index': 'pdf_indexing_docwise_temp', '_id': '0', '_version': 2, '_type': 'documents', '_shards': {'failed': 0, 'total': 1, 'successful': 1}}'\n",
      " response: '{'_index': 'pdf_indexing_docwise_temp', '_id': '0', '_version': 3, '_type': 'documents', '_shards': {'failed': 0, 'total': 1, 'successful': 1}}'\n"
     ]
    }
   ],
   "source": [
    "# document content need to be updated\n",
    "\n",
    "#data with updating exsisting content\n",
    "data = {\"doc\":\n",
    "        {\"content\": \"blah blah blah blah....\",\n",
    "         \"date\": \"14/12/2016\"\n",
    "        }\n",
    "       }\n",
    "\n",
    "# data with updating and adding new field\n",
    "# Note: As mensioned earlier, for new field, mapping is derived by default. In this case, \"string\"\n",
    "data2 = {\"doc\":\n",
    "         {\"new_field\": \"new feild content\"}\n",
    "        }\n",
    "         \n",
    "# update data\n",
    "\n",
    "doc_id = \"0\"\n",
    "res = es.update(index = INDEX_NAME, body = data ,doc_type = TYPE_NAME ,id = doc_id, refresh = True)\n",
    "print(\" response: '%s'\" % (res))\n",
    "\n",
    "# update data2\n",
    "\n",
    "res = es.update(index = INDEX_NAME, body = data2 ,doc_type = TYPE_NAME ,id = doc_id, refresh = True)\n",
    "print(\" response: '%s'\" % (res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample query\n",
    "\n",
    "Simple query to select all the results and subset of fields in the data. Please refer official documentation of complete understanding for queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# query to select all the entries and only title and content fields\n",
    "my_query = \"\"\"{\n",
    "  \"fields\": [\n",
    "     \"title\",\"content\"\n",
    "  ], \n",
    "  \"query\": {\"match_all\":{}}\n",
    "  }\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search in a index\n",
    "\n",
    "Given an query, search through the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 documents found\n",
      "0 : ['tile_name']\n"
     ]
    }
   ],
   "source": [
    "res = es.search(index=INDEX_NAME, doc_type=TYPE_NAME, body=my_query)\n",
    "print(\"%d documents found\" % res['hits']['total'])\n",
    "\n",
    "# print the content\n",
    "for doc in res['hits']['hits']:\n",
    "    print(\"%s : %s\" % (doc['_id'], doc['fields']['title']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrolling through the index to get complete content\n",
    "\n",
    "This is very useful when complete data needed to analysis and transform for selected/all fields.\n",
    "\n",
    "Below is a scroll function which preforms n_gram tokenization scrolling through complete index data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def es_scroll():\n",
    "\n",
    "    # Function scroll through all the documents in current index and returns content\n",
    "\n",
    "    scroll = helpers.scan(\n",
    "            es,\n",
    "            index=INDEX_NAME,\n",
    "            doc_type=TYPE_NAME,\n",
    "            size = 1000,\n",
    "            scroll = '5m', \n",
    "            query={\n",
    "            \"fields\": [\"title\",\"content\"],\n",
    "            \"query\": {\"match_all\":{}}\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    \n",
    "    top_keywords = {}\n",
    "    count = 0\n",
    "    for doc in scroll:\n",
    "        count += 1\n",
    "        print(count)\n",
    "        \n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bulk indexing \n",
    "\n",
    "If indexing many documnets together, always use bulk indexing. It will reduce time significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexed 5 docs\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import helpers\n",
    "\n",
    "actions = []\n",
    "\n",
    "for text in [{\"content\":\"dac\"},{\"content\":\"dsafa\"},{\"content\":\"adsf\"}]:\n",
    "    doc_id = text[\"id\"]\n",
    "    action = {\n",
    "        \"_index\": INDEX_NAME,\n",
    "        \"_type\": TYPE_NAME,\n",
    "        \"_id\": doc_id,\n",
    "        \"_source\": text\n",
    "        }\n",
    "\n",
    "    actions.append(action)\n",
    "\n",
    "print(time.time() - start)\n",
    "start = time.time()\n",
    "\n",
    "if len(actions) > 0:\n",
    "    helpers.bulk(es, actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Bulk indexing for steaming data\n",
    "\n",
    "There are two functions, streaming_bulk and parallel_bulk for indexing streaming data\n",
    "\n",
    "Below code only indicate how to use above api's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_actions():\n",
    "    for text in wr.records(min_len=100,limit=5000):\n",
    "        doc_id = text[\"page_id\"]\n",
    "        yield {\n",
    "            \"_index\": INDEX_NAME,\n",
    "            \"_type\": TYPE_NAME,\n",
    "            \"_id\": doc_id,\n",
    "            \"_source\": text\n",
    "            }\n",
    "\n",
    "for success, info in helpers.parallel_bulk(es, generate_actions(),thread_count=4):\n",
    "    if not success: print('Doc failed', info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
